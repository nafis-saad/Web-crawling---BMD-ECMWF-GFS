{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_network_basic.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nafis-saad/Web-crawling---BMD-ECMWF-GFS/blob/main/Neural_network_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vkcC3hkmjlrD",
        "outputId": "bab56fd8-636f-4106-f6eb-dbf6ba8c7a34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n- tensorflow\\n- keras\\n\\n- pytorch\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "- tensorflow\n",
        "- keras\n",
        "\n",
        "- pytorch\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "\n",
        "load_data = load_breast_cancer()\n",
        "target_data = load_breast_cancer().target\n",
        "\n",
        "input_data = pd.DataFrame(data=load_data.data, columns=load_data.feature_names)\n",
        "input_data['Label'] = target_data\n",
        "\n",
        "input_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "sCjL6xWAnbaD",
        "outputId": "89e58b34-fd7e-4a9f-dba9-8e020e598a49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
              "0                   0.07871  ...          17.33           184.60      2019.0   \n",
              "1                   0.05667  ...          23.41           158.80      1956.0   \n",
              "2                   0.05999  ...          25.53           152.50      1709.0   \n",
              "3                   0.09744  ...          26.50            98.87       567.7   \n",
              "4                   0.05883  ...          16.67           152.20      1575.0   \n",
              "..                      ...  ...            ...              ...         ...   \n",
              "564                 0.05623  ...          26.40           166.10      2027.0   \n",
              "565                 0.05533  ...          38.25           155.00      1731.0   \n",
              "566                 0.05648  ...          34.12           126.70      1124.0   \n",
              "567                 0.07016  ...          39.42           184.60      1821.0   \n",
              "568                 0.05884  ...          30.37            59.16       268.6   \n",
              "\n",
              "     worst smoothness  worst compactness  worst concavity  \\\n",
              "0             0.16220            0.66560           0.7119   \n",
              "1             0.12380            0.18660           0.2416   \n",
              "2             0.14440            0.42450           0.4504   \n",
              "3             0.20980            0.86630           0.6869   \n",
              "4             0.13740            0.20500           0.4000   \n",
              "..                ...                ...              ...   \n",
              "564           0.14100            0.21130           0.4107   \n",
              "565           0.11660            0.19220           0.3215   \n",
              "566           0.11390            0.30940           0.3403   \n",
              "567           0.16500            0.86810           0.9387   \n",
              "568           0.08996            0.06444           0.0000   \n",
              "\n",
              "     worst concave points  worst symmetry  worst fractal dimension  Label  \n",
              "0                  0.2654          0.4601                  0.11890      0  \n",
              "1                  0.1860          0.2750                  0.08902      0  \n",
              "2                  0.2430          0.3613                  0.08758      0  \n",
              "3                  0.2575          0.6638                  0.17300      0  \n",
              "4                  0.1625          0.2364                  0.07678      0  \n",
              "..                    ...             ...                      ...    ...  \n",
              "564                0.2216          0.2060                  0.07115      0  \n",
              "565                0.1628          0.2572                  0.06637      0  \n",
              "566                0.1418          0.2218                  0.07820      0  \n",
              "567                0.2650          0.4087                  0.12400      0  \n",
              "568                0.0000          0.2871                  0.07039      1  \n",
              "\n",
              "[569 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da210e68-966e-4e64-8b6b-c4e55af218e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da210e68-966e-4e64-8b6b-c4e55af218e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da210e68-966e-4e64-8b6b-c4e55af218e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da210e68-966e-4e64-8b6b-c4e55af218e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29TU_gm-o-Tx",
        "outputId": "850870ba-11e3-43cb-b2c0-ea0e39aacf5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "mean radius                0\n",
              "mean texture               0\n",
              "mean perimeter             0\n",
              "mean area                  0\n",
              "mean smoothness            0\n",
              "mean compactness           0\n",
              "mean concavity             0\n",
              "mean concave points        0\n",
              "mean symmetry              0\n",
              "mean fractal dimension     0\n",
              "radius error               0\n",
              "texture error              0\n",
              "perimeter error            0\n",
              "area error                 0\n",
              "smoothness error           0\n",
              "compactness error          0\n",
              "concavity error            0\n",
              "concave points error       0\n",
              "symmetry error             0\n",
              "fractal dimension error    0\n",
              "worst radius               0\n",
              "worst texture              0\n",
              "worst perimeter            0\n",
              "worst area                 0\n",
              "worst smoothness           0\n",
              "worst compactness          0\n",
              "worst concavity            0\n",
              "worst concave points       0\n",
              "worst symmetry             0\n",
              "worst fractal dimension    0\n",
              "Label                      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = input_data.drop(\"Label\", axis=1)\n",
        "y = input_data[\"Label\"]"
      ],
      "metadata": {
        "id": "EI-L-GGzqYrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split into train & test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, # independent variables \n",
        "                                                    y, # dependent variable\n",
        "                                                    test_size = 0.2) # percentage of data to use for test set"
      ],
      "metadata": {
        "id": "CrUUbDc0qslo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "NK3kPxKDq7b1",
        "outputId": "961f10e1-f4a8-4e25-9052-7b92dfb4544f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "425        10.03         21.28           63.19      307.3          0.08117   \n",
              "158        12.06         12.74           76.84      448.6          0.09311   \n",
              "310        11.70         19.11           74.33      418.7          0.08814   \n",
              "560        14.05         27.15           91.38      600.4          0.09929   \n",
              "472        14.92         14.93           96.45      686.9          0.08098   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "229        12.83         22.33           85.26      503.2          0.10880   \n",
              "215        13.86         16.93           90.96      578.9          0.10260   \n",
              "395        14.06         17.18           89.75      609.1          0.08045   \n",
              "100        13.61         24.98           88.05      582.7          0.09488   \n",
              "207        17.01         20.26          109.70      904.3          0.08772   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "425           0.03912         0.00247             0.005159         0.1630   \n",
              "158           0.05241         0.01972             0.019630         0.1590   \n",
              "310           0.05253         0.01583             0.011480         0.1936   \n",
              "560           0.11260         0.04462             0.043040         0.1537   \n",
              "472           0.08549         0.05539             0.032210         0.1687   \n",
              "..                ...             ...                  ...            ...   \n",
              "229           0.17990         0.16950             0.068610         0.2123   \n",
              "215           0.15170         0.09901             0.056020         0.2106   \n",
              "395           0.05361         0.02681             0.032510         0.1641   \n",
              "100           0.08511         0.08625             0.044890         0.1609   \n",
              "207           0.07304         0.06950             0.053900         0.2026   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "425                 0.06439  ...         11.11          28.94   \n",
              "158                 0.05907  ...         13.14          18.41   \n",
              "310                 0.06128  ...         12.61          26.55   \n",
              "560                 0.06171  ...         15.30          33.17   \n",
              "472                 0.05669  ...         17.18          18.22   \n",
              "..                      ...  ...           ...            ...   \n",
              "229                 0.07254  ...         15.20          30.15   \n",
              "215                 0.06916  ...         15.75          26.93   \n",
              "395                 0.05764  ...         14.92          25.34   \n",
              "100                 0.05871  ...         16.99          35.27   \n",
              "207                 0.05223  ...         19.80          25.05   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "425            69.92       376.3            0.1126            0.07094   \n",
              "158            84.08       532.8            0.1275            0.12320   \n",
              "310            80.92       483.1            0.1223            0.10870   \n",
              "560           100.20       706.7            0.1241            0.22640   \n",
              "472           112.00       906.6            0.1065            0.27910   \n",
              "..               ...         ...               ...                ...   \n",
              "229           105.30       706.0            0.1777            0.53430   \n",
              "215           104.40       750.1            0.1460            0.43700   \n",
              "395            96.42       684.5            0.1066            0.12310   \n",
              "100           108.60       906.5            0.1265            0.19430   \n",
              "207           130.00      1210.0            0.1111            0.14860   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "425          0.01235               0.02579          0.2349   \n",
              "158          0.08636               0.07025          0.2514   \n",
              "310          0.07915               0.05741          0.3487   \n",
              "560          0.13260               0.10480          0.2250   \n",
              "472          0.31510               0.11470          0.2688   \n",
              "..               ...                   ...             ...   \n",
              "229          0.62820               0.19770          0.3407   \n",
              "215          0.46360               0.16540          0.3630   \n",
              "395          0.08460               0.07911          0.2523   \n",
              "100          0.31690               0.11840          0.2651   \n",
              "207          0.19320               0.10960          0.3275   \n",
              "\n",
              "     worst fractal dimension  \n",
              "425                  0.08061  \n",
              "158                  0.07898  \n",
              "310                  0.06958  \n",
              "560                  0.08321  \n",
              "472                  0.08273  \n",
              "..                       ...  \n",
              "229                  0.12430  \n",
              "215                  0.10590  \n",
              "395                  0.06609  \n",
              "100                  0.07397  \n",
              "207                  0.06469  \n",
              "\n",
              "[455 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95a130b5-784f-44f3-985c-02efb54a0d57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>10.03</td>\n",
              "      <td>21.28</td>\n",
              "      <td>63.19</td>\n",
              "      <td>307.3</td>\n",
              "      <td>0.08117</td>\n",
              "      <td>0.03912</td>\n",
              "      <td>0.00247</td>\n",
              "      <td>0.005159</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.06439</td>\n",
              "      <td>...</td>\n",
              "      <td>11.11</td>\n",
              "      <td>28.94</td>\n",
              "      <td>69.92</td>\n",
              "      <td>376.3</td>\n",
              "      <td>0.1126</td>\n",
              "      <td>0.07094</td>\n",
              "      <td>0.01235</td>\n",
              "      <td>0.02579</td>\n",
              "      <td>0.2349</td>\n",
              "      <td>0.08061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>12.06</td>\n",
              "      <td>12.74</td>\n",
              "      <td>76.84</td>\n",
              "      <td>448.6</td>\n",
              "      <td>0.09311</td>\n",
              "      <td>0.05241</td>\n",
              "      <td>0.01972</td>\n",
              "      <td>0.019630</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05907</td>\n",
              "      <td>...</td>\n",
              "      <td>13.14</td>\n",
              "      <td>18.41</td>\n",
              "      <td>84.08</td>\n",
              "      <td>532.8</td>\n",
              "      <td>0.1275</td>\n",
              "      <td>0.12320</td>\n",
              "      <td>0.08636</td>\n",
              "      <td>0.07025</td>\n",
              "      <td>0.2514</td>\n",
              "      <td>0.07898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>11.70</td>\n",
              "      <td>19.11</td>\n",
              "      <td>74.33</td>\n",
              "      <td>418.7</td>\n",
              "      <td>0.08814</td>\n",
              "      <td>0.05253</td>\n",
              "      <td>0.01583</td>\n",
              "      <td>0.011480</td>\n",
              "      <td>0.1936</td>\n",
              "      <td>0.06128</td>\n",
              "      <td>...</td>\n",
              "      <td>12.61</td>\n",
              "      <td>26.55</td>\n",
              "      <td>80.92</td>\n",
              "      <td>483.1</td>\n",
              "      <td>0.1223</td>\n",
              "      <td>0.10870</td>\n",
              "      <td>0.07915</td>\n",
              "      <td>0.05741</td>\n",
              "      <td>0.3487</td>\n",
              "      <td>0.06958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>14.05</td>\n",
              "      <td>27.15</td>\n",
              "      <td>91.38</td>\n",
              "      <td>600.4</td>\n",
              "      <td>0.09929</td>\n",
              "      <td>0.11260</td>\n",
              "      <td>0.04462</td>\n",
              "      <td>0.043040</td>\n",
              "      <td>0.1537</td>\n",
              "      <td>0.06171</td>\n",
              "      <td>...</td>\n",
              "      <td>15.30</td>\n",
              "      <td>33.17</td>\n",
              "      <td>100.20</td>\n",
              "      <td>706.7</td>\n",
              "      <td>0.1241</td>\n",
              "      <td>0.22640</td>\n",
              "      <td>0.13260</td>\n",
              "      <td>0.10480</td>\n",
              "      <td>0.2250</td>\n",
              "      <td>0.08321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>14.92</td>\n",
              "      <td>14.93</td>\n",
              "      <td>96.45</td>\n",
              "      <td>686.9</td>\n",
              "      <td>0.08098</td>\n",
              "      <td>0.08549</td>\n",
              "      <td>0.05539</td>\n",
              "      <td>0.032210</td>\n",
              "      <td>0.1687</td>\n",
              "      <td>0.05669</td>\n",
              "      <td>...</td>\n",
              "      <td>17.18</td>\n",
              "      <td>18.22</td>\n",
              "      <td>112.00</td>\n",
              "      <td>906.6</td>\n",
              "      <td>0.1065</td>\n",
              "      <td>0.27910</td>\n",
              "      <td>0.31510</td>\n",
              "      <td>0.11470</td>\n",
              "      <td>0.2688</td>\n",
              "      <td>0.08273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>12.83</td>\n",
              "      <td>22.33</td>\n",
              "      <td>85.26</td>\n",
              "      <td>503.2</td>\n",
              "      <td>0.10880</td>\n",
              "      <td>0.17990</td>\n",
              "      <td>0.16950</td>\n",
              "      <td>0.068610</td>\n",
              "      <td>0.2123</td>\n",
              "      <td>0.07254</td>\n",
              "      <td>...</td>\n",
              "      <td>15.20</td>\n",
              "      <td>30.15</td>\n",
              "      <td>105.30</td>\n",
              "      <td>706.0</td>\n",
              "      <td>0.1777</td>\n",
              "      <td>0.53430</td>\n",
              "      <td>0.62820</td>\n",
              "      <td>0.19770</td>\n",
              "      <td>0.3407</td>\n",
              "      <td>0.12430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>13.86</td>\n",
              "      <td>16.93</td>\n",
              "      <td>90.96</td>\n",
              "      <td>578.9</td>\n",
              "      <td>0.10260</td>\n",
              "      <td>0.15170</td>\n",
              "      <td>0.09901</td>\n",
              "      <td>0.056020</td>\n",
              "      <td>0.2106</td>\n",
              "      <td>0.06916</td>\n",
              "      <td>...</td>\n",
              "      <td>15.75</td>\n",
              "      <td>26.93</td>\n",
              "      <td>104.40</td>\n",
              "      <td>750.1</td>\n",
              "      <td>0.1460</td>\n",
              "      <td>0.43700</td>\n",
              "      <td>0.46360</td>\n",
              "      <td>0.16540</td>\n",
              "      <td>0.3630</td>\n",
              "      <td>0.10590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>14.06</td>\n",
              "      <td>17.18</td>\n",
              "      <td>89.75</td>\n",
              "      <td>609.1</td>\n",
              "      <td>0.08045</td>\n",
              "      <td>0.05361</td>\n",
              "      <td>0.02681</td>\n",
              "      <td>0.032510</td>\n",
              "      <td>0.1641</td>\n",
              "      <td>0.05764</td>\n",
              "      <td>...</td>\n",
              "      <td>14.92</td>\n",
              "      <td>25.34</td>\n",
              "      <td>96.42</td>\n",
              "      <td>684.5</td>\n",
              "      <td>0.1066</td>\n",
              "      <td>0.12310</td>\n",
              "      <td>0.08460</td>\n",
              "      <td>0.07911</td>\n",
              "      <td>0.2523</td>\n",
              "      <td>0.06609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>13.61</td>\n",
              "      <td>24.98</td>\n",
              "      <td>88.05</td>\n",
              "      <td>582.7</td>\n",
              "      <td>0.09488</td>\n",
              "      <td>0.08511</td>\n",
              "      <td>0.08625</td>\n",
              "      <td>0.044890</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.05871</td>\n",
              "      <td>...</td>\n",
              "      <td>16.99</td>\n",
              "      <td>35.27</td>\n",
              "      <td>108.60</td>\n",
              "      <td>906.5</td>\n",
              "      <td>0.1265</td>\n",
              "      <td>0.19430</td>\n",
              "      <td>0.31690</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.2651</td>\n",
              "      <td>0.07397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>17.01</td>\n",
              "      <td>20.26</td>\n",
              "      <td>109.70</td>\n",
              "      <td>904.3</td>\n",
              "      <td>0.08772</td>\n",
              "      <td>0.07304</td>\n",
              "      <td>0.06950</td>\n",
              "      <td>0.053900</td>\n",
              "      <td>0.2026</td>\n",
              "      <td>0.05223</td>\n",
              "      <td>...</td>\n",
              "      <td>19.80</td>\n",
              "      <td>25.05</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1210.0</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.14860</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.3275</td>\n",
              "      <td>0.06469</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>455 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95a130b5-784f-44f3-985c-02efb54a0d57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95a130b5-784f-44f3-985c-02efb54a0d57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95a130b5-784f-44f3-985c-02efb54a0d57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b3vlOIwvONG",
        "outputId": "3ad2b533-9f20-4375-d051-b0976a32025a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(455, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "input (30) -> layer(Dense, 12) -> layer(Dense, 8) -> layer(Dense, 1)\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim = X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train,y_train, validation_data=(X_test,y_test), epochs=150, batch_size=10, verbose=0)"
      ],
      "metadata": {
        "id": "qQZ-VuuerCgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model_accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XhxIi5VIy4Af",
        "outputId": "dc85f3b3-e064-4ced-c877-5da55af58d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_score = max(history.history['accuracy'])\n",
        "\n",
        "best_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiZYasK4zcxF",
        "outputId": "6c0b2d95-aec9-4ab6-db67-0bae8384bb69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9604395627975464"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "## Result\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Put models in a dictionary\n",
        "models = {\"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "          \"Logistic Regression\": LogisticRegression(), \n",
        "          \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "         \"Linear Support Vector\" : SVC(kernel='rbf', C=1, gamma=1),\n",
        "         \"naive_bayes\": GaussianNB(),\n",
        "         \"Decision tree\": DecisionTreeClassifier(),\n",
        "          \"XGBoost\" : XGBClassifier()\n",
        "            }\n",
        "\n",
        "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Fits and evaluates given machine learning models.\n",
        "    models : a dict of different Scikit-Learn machine learning models\n",
        "    X_train : training data\n",
        "    X_test : testing data\n",
        "    y_train : labels assosciated with training data\n",
        "    y_test : labels assosciated with test data\n",
        "    \"\"\"\n",
        "    \n",
        "    # Make a list to keep model scores\n",
        "    model_scores = {}\n",
        "    model_classification = {}\n",
        "    model_confusion = {}\n",
        "    \n",
        "    # Loop through models\n",
        "    for name, model in models.items():\n",
        "        # Fit the model to the data\n",
        "        model.fit(X_train, y_train)\n",
        "        # Evaluate the model and append its score to model_scores\n",
        "        model_scores[name] = model.score(X_test, y_test)\n",
        "        y_preds = model.predict(X_test)\n",
        "        model_confusion[name] = confusion_matrix(y_test,y_preds)\n",
        "        model_classification[name] = classification_report(y_test,y_preds)\n",
        "    return model_scores,model_classification,model_confusion"
      ],
      "metadata": {
        "id": "kXFsg6ysz4l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_scores,model_classification,model_confusion = fit_and_score(models=models,\n",
        "                             X_train=X_train,\n",
        "                             X_test=X_test,\n",
        "                             y_train=y_train,\n",
        "                             y_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGuqKDrfz7EY",
        "outputId": "2259b60c-e01b-42cb-ccad-97f581762550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMOoRMY3z8ob",
        "outputId": "67a08132-64c2-4c8f-98ec-235dbc305ad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Decision tree': 0.8947368421052632,\n",
              " 'KNN': 0.9210526315789473,\n",
              " 'Linear Support Vector': 0.5964912280701754,\n",
              " 'Logistic Regression': 0.9298245614035088,\n",
              " 'Random Forest': 0.956140350877193,\n",
              " 'XGBoost': 0.9385964912280702,\n",
              " 'naive_bayes': 0.9385964912280702}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Approach:\n",
        "\n",
        "Dataset -> Preprocess -> Data analysis(corr, column graph) -> k-fold -> traditional ML (score)\n",
        "                                                           -> k-fold -> Neural Network (score)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "ekGSI4zz0gJC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0930e31a-c0d9-4447-fe44-2ce6d2a58703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nApproach:\\n\\nDataset -> Preprocess -> Data analysis(corr, column graph) -> k-fold -> traditional ML (score)\\n                                                           -> k-fold -> Neural Network (score)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}